{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('./dataset/text/text.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_text_pairs = dict(zip(df['image_name'], df['text_explanation']))\n",
    "img_text_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "mllm_data=[]\n",
    "base_img_path='/home/chuannong1/KJY/MultiLLM/dataset/image/'\n",
    "for i in img_text_pairs:\n",
    "    dict_temp=dict()\n",
    "    dict_temp['messages']=[{\"content\": \"<image>根据上传的医学影像进行诊断\",\"role\": \"user\"},\n",
    "                           {\"content\": img_text_pairs[i],\"role\": \"assistant\"}]\n",
    "    dict_temp['images']=[os.path.join(base_img_path,str(i)+'.jpg')]\n",
    "    mllm_data.append(dict_temp)\n",
    "\n",
    "mllm_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def prompt_template_pt(img_path,text):\n",
    "    dict_temp=dict()\n",
    "    dict_temp['messages']=[{\"content\": \"<image>医学影像诊断结果:\",\"role\": \"user\"},\n",
    "                           {\"content\": text,\"role\": \"assistant\"}]\n",
    "    dict_temp['images']=[img_path]\n",
    "\n",
    "    return dict_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def img_text_pair_pt(data_dir):\n",
    "    mllm_data_temp=[]\n",
    "    patient_img_dir=os.path.join(data_dir,'datajpg')\n",
    "    patient_id_list=os.listdir(patient_img_dir)\n",
    "    df_patient_fp=os.path.join(data_dir,'病理描述文本.xlsx')\n",
    "    df_patient=pd.read_excel(df_patient_fp)\n",
    "    for patient_id in patient_id_list:\n",
    "        patient_id_img_dir=os.path.join(patient_img_dir,patient_id)\n",
    "        for img_id in os.listdir(patient_id_img_dir):\n",
    "            img_path=os.path.join(patient_id_img_dir,img_id)\n",
    "            patient_id_int = int(patient_id)\n",
    "\n",
    "            if patient_id_int in df_patient['id'].values:\n",
    "                text = df_patient[df_patient['id'] == patient_id_int]['text'].values[0]\n",
    "                dict_temp=prompt_template_pt(img_path,text)\n",
    "                mllm_data_temp.append(dict_temp)\n",
    "\n",
    "    return mllm_data_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chongyisan开始处理\n",
      "chongyisan完成\n",
      "jidafuyuan4开始处理\n",
      "jidafuyuan4完成\n",
      "luzhouzhongyi6开始处理\n",
      "luzhouzhongyi6完成\n",
      "chongyier1开始处理\n",
      "chongyier1完成\n",
      "nanchongzhongxinyiyuan8开始处理\n",
      "nanchongzhongxinyiyuan8完成\n",
      "leshanzhongyi5开始处理\n",
      "leshanzhongyi5完成\n",
      "fudanzhongshan3开始处理\n",
      "fudanzhongshan3完成\n",
      "mianyangsanyuan7开始处理\n",
      "mianyangsanyuan7完成\n",
      "chongyiyi2开始处理\n",
      "chongyiyi2完成\n"
     ]
    }
   ],
   "source": [
    "base_path=\"/mnt/newdisk/MultiLLMdata/data/train\"\n",
    "mllm_data=[]\n",
    "for dir_name in os.listdir(base_path):\n",
    "    print(f'{dir_name}开始处理')\n",
    "    dir_path=os.path.join(base_path,dir_name)\n",
    "    mllm_data = mllm_data + img_text_pair_pt(dir_path)\n",
    "    print(f'{dir_name}完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 将字典转换为 JSON 字符串\n",
    "json_string = json.dumps(mllm_data, ensure_ascii=False, indent=4)\n",
    "# 如果需要将 JSON 保存到文件\n",
    "with open('./LLaMA-Factory/data/mllm_pt.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(mllm_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRA微调"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def prompt_template(img_path,text):\n",
    "    dict_temp=dict()\n",
    "    dict_temp['messages']=[{\"content\": \"You are a medical imaging diagnosis assistant. Please answer user questions in professional language.\",\"role\": \"system\"},\n",
    "                           {\"content\": \"<image>Diagnose based on uploaded medical images:\",\"role\": \"user\"},\n",
    "                           {\"content\": text,\"role\": \"assistant\"}]\n",
    "    dict_temp['images']=[img_path]\n",
    "\n",
    "    return dict_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def img_text_pair(data_dir):\n",
    "    mllm_data_temp=[]\n",
    "    patient_img_dir=os.path.join(data_dir,'datajpg')\n",
    "    patient_id_list=os.listdir(patient_img_dir)\n",
    "    df_patient_fp=os.path.join(data_dir,'病理描述文本en.xlsx')\n",
    "    df_patient=pd.read_excel(df_patient_fp)\n",
    "    for patient_id in patient_id_list:\n",
    "        patient_id_img_dir=os.path.join(patient_img_dir,patient_id)\n",
    "        for img_id in os.listdir(patient_id_img_dir):\n",
    "            img_path=os.path.join(patient_id_img_dir,img_id)\n",
    "            patient_id_int = int(patient_id)\n",
    "\n",
    "            if patient_id_int in df_patient['id'].values:\n",
    "                text = df_patient[df_patient['id'] == patient_id_int]['text'].values[0]\n",
    "                dict_temp=prompt_template(img_path,text)\n",
    "                mllm_data_temp.append(dict_temp)\n",
    "\n",
    "    return mllm_data_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yibineryuan9开始处理\n",
      "yibineryuan9完成\n"
     ]
    }
   ],
   "source": [
    "base_path=\"/mnt/newdisk/MultiLLMdata/data/val\"\n",
    "mllm_data=[]\n",
    "for dir_name in os.listdir(base_path):\n",
    "    print(f'{dir_name}开始处理')\n",
    "    dir_path=os.path.join(base_path,dir_name)\n",
    "    mllm_data = mllm_data + img_text_pair(dir_path)\n",
    "    print(f'{dir_name}完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 将字典转换为 JSON 字符串\n",
    "json_string = json.dumps(mllm_data, ensure_ascii=False, indent=4)\n",
    "# 如果需要将 JSON 保存到文件\n",
    "with open('./LLaMA-Factory/data/mllm_val_en.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(mllm_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MS-SWIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def prompt_template(img_path_list,text,seq_len):\n",
    "    dict_temp=dict()\n",
    "    img_special_token='<image>'\n",
    "    dict_temp={\"system\": \"你是医学影像诊断小助手,请用专业的语言回答用户问题\",\n",
    "               \"query\": f\"这是一串连续的医学影像：{img_special_token*seq_len}。请根据上传医学影像进行诊断\",\n",
    "               \"response\": text,\n",
    "               \"history\": [],\n",
    "               \"images\":img_path_list}\n",
    "\n",
    "    return dict_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def img_text_pair(data_dir):\n",
    "    mllm_data_temp=[]\n",
    "    patient_img_dir=os.path.join(data_dir,'datajpg')\n",
    "    patient_id_list=os.listdir(patient_img_dir)\n",
    "    df_patient_fp=os.path.join(data_dir,'病理描述文本.xlsx')\n",
    "    df_patient=pd.read_excel(df_patient_fp)\n",
    "    for patient_id in patient_id_list:\n",
    "        img_path_list=[]\n",
    "        patient_id_img_dir=os.path.join(patient_img_dir,patient_id)\n",
    "        for img_id in sorted(os.listdir(patient_id_img_dir),key=lambda x: int(re.findall(r'\\d+', x)[0])):\n",
    "            img_path=os.path.join(patient_id_img_dir,img_id)\n",
    "            patient_id_int = int(patient_id)\n",
    "            img_path_list.append(img_path)\n",
    "\n",
    "        if patient_id_int in df_patient['id'].values:\n",
    "            text = df_patient[df_patient['id'] == patient_id_int]['text'].values[0]\n",
    "        \n",
    "        seq_len=len(img_path_list)\n",
    "        dict_temp=prompt_template(img_path_list,text,seq_len)\n",
    "        mllm_data_temp.append(dict_temp)\n",
    "\n",
    "    return mllm_data_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mllm_data_temp=img_text_pair(\"/mnt/newdisk/MultiLLMdata/data/train/chongyier1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chongyisan开始处理\n",
      "chongyisan完成\n",
      "jidafuyuan4开始处理\n",
      "jidafuyuan4完成\n",
      "luzhouzhongyi6开始处理\n",
      "luzhouzhongyi6完成\n",
      "chongyier1开始处理\n",
      "chongyier1完成\n",
      "nanchongzhongxinyiyuan8开始处理\n",
      "nanchongzhongxinyiyuan8完成\n",
      "leshanzhongyi5开始处理\n",
      "leshanzhongyi5完成\n",
      "fudanzhongshan3开始处理\n",
      "fudanzhongshan3完成\n",
      "mianyangsanyuan7开始处理\n",
      "mianyangsanyuan7完成\n",
      "chongyiyi2开始处理\n",
      "chongyiyi2完成\n"
     ]
    }
   ],
   "source": [
    "base_path=\"/mnt/newdisk/MultiLLMdata/data/train\"\n",
    "mllm_data=[]\n",
    "for dir_name in os.listdir(base_path):\n",
    "    print(f'{dir_name}开始处理')\n",
    "    dir_path=os.path.join(base_path,dir_name)\n",
    "    mllm_data = mllm_data + img_text_pair(dir_path)\n",
    "    print(f'{dir_name}完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 将列表转换为 JSON 并写入文件\n",
    "with open(\"./ms-swift/data/qwen2_vl_train.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "    for item in mllm_data:\n",
    "        json.dump(item, json_file, ensure_ascii=False)\n",
    "        json_file.write(\"\\n\")  # 每个对象占一行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yibineryuan9开始处理\n",
      "yibineryuan9完成\n"
     ]
    }
   ],
   "source": [
    "base_path=\"/mnt/newdisk/MultiLLMdata/data/val\"\n",
    "mllm_data=[]\n",
    "for dir_name in os.listdir(base_path):\n",
    "    print(f'{dir_name}开始处理')\n",
    "    dir_path=os.path.join(base_path,dir_name)\n",
    "    mllm_data = mllm_data + img_text_pair(dir_path)\n",
    "    print(f'{dir_name}完成')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 将列表转换为 JSON 并写入文件\n",
    "with open(\"./ms-swift/data/qwen2_vl_val.json\", \"w\", encoding=\"utf-8\") as json_file:\n",
    "    for item in mllm_data:\n",
    "        json.dump(item, json_file, ensure_ascii=False)\n",
    "        json_file.write(\"\\n\")  # 每个对象占一行"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_factory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
