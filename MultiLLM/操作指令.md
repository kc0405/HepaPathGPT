# 操作指令

## 安装

```bash
cd /home/chuannong1/KJY/MultiLLM
git clone https://github.com/hiyouga/LLaMA-Factory.git
conda create -n llama_factory python=3.10
conda activate llama_factory
cd LLaMA-Factory
pip install -e '.[torch,metrics]'


```
## 模型下载

```bash
conda activate llama_factory
cd /home/chuannong1/KJY/MultiLLM/LLaMA-Factory

export HF_ENDPOINT=https://hf-mirror.com
huggingface-cli download --resume-download llava-hf/llava-1.5-7b-hf --local-dir llava-hf/llava-1.5-7b-hf
huggingface-cli download --resume-download llava-hf/llava-1.5-13b-hf --local-dir llava-hf/llava-1.5-13b-hf
huggingface-cli download --resume-download Qwen/Qwen2-VL-7B-Instruct --local-dir /mnt/newdisk/MultiLLM_models/Qwen/Qwen2-VL-7B-Instruct
huggingface-cli download --resume-download microsoft/llava-med-v1.5-mistral-7b --local-dir microsoft/llava-med-v1.5-mistral-7b
huggingface-cli download --resume-download kms-healthcare/llava-med --local-dir kms-healthcare/llava-med
huggingface-cli download --resume-download BUAADreamer/Chinese-LLaVA-Med-7B --local-dir BUAADreamer/Chinese-LLaVA-Med-7B
```


## 预训练

```bash
cd /home/chuannong1/KJY/MultiLLM/LLaMA-Factory
conda activate llama_factory
CUDA_VISIBLE_DEVICES=0,1,2,3,4 llamafactory-cli train config/llava_pt.yaml

cd /home/chuannong1/KJY/MultiLLM/LLaMA-Factory
conda activate llama_factory
CUDA_VISIBLE_DEVICES=0,1,2,3,4 llamafactory-cli train config/Qwenvl7B_pt.yaml
```

## deepspeed offload

```bash
## 更新gcc,只在终端生效
export CC=/home/chuannong1/anaconda3/envs/llama_factory/bin/gcc
export CXX=/home/chuannong1/anaconda3/envs/llama_factory/bin/g++
```

## 微调
·
```bash

## 微调 llava-7B
cd /home/chuannong1/KJY/MultiLLM/LLaMA-Factory
conda activate llama_factory
CUDA_VISIBLE_DEVICES=1,2,3 llamafactory-cli train config/llava_lora_sft.yaml

## 微调 llava-13B
cd /home/chuannong1/KJY/MultiLLM/LLaMA-Factory
conda activate llama_factory
CUDA_VISIBLE_DEVICES=0,1,2,3,4 llamafactory-cli train config/llava_lora_sft_llava_13B.yaml

## 微调 Qwen2-VL-7B
cd /home/chuannong1/KJY/MultiLLM/LLaMA-Factory
conda activate llama_factory
CUDA_VISIBLE_DEVICES=1,2,3 llamafactory-cli train config/lora_sft_Qwen2vl_7B.yaml

## 微调 llava-med-7B
cd /home/chuannong1/KJY/MultiLLM/LLaMA-Factory
conda activate llama_factory
CUDA_VISIBLE_DEVICES=0,1,2,3 llamafactory-cli train config/llava_med_lora_sft.yaml
```

## 进入webui

```bash
cd /home/chuannong1/KJY/MultiLLM/LLaMA-Factory
conda activate llama_factory
llamafactory-cli webui
```

## 合并

```bash
cd /home/chuannong1/KJY/MultiLLM/LLaMA-Factory
conda activate llama_factory
CUDA_VISIBLE_DEVICES=1,2,3 llamafactory-cli export config/merge_config.yaml
```

## eval

```bash
cd /home/chuannong1/KJY/MultiLLM/LLaMA-Factory
conda activate llama_factory
CUDA_VISIBLE_DEVICES=0,1,2,3 llamafactory-cli train config/llava_med_eval.yaml
```

```bash
cd /home/chuannong1/KJY/MultiLLM/LLaMA-Factory
conda activate llama_factory
CUDA_VISIBLE_DEVICES=0,1,2,3 llamafactory-cli train config/llava_en_eval.yaml
```

```bash
cd /home/chuannong1/KJY/MultiLLM/LLaMA-Factory
conda activate llama_factory
CUDA_VISIBLE_DEVICES=0,1,2,3 llamafactory-cli train config/llava_med_en_eval.yaml
```

## webchat

```bash
cd /home/chuannong1/KJY/MultiLLM/LLaMA-Factory
conda activate llama_factory
CUDA_VISIBLE_DEVICES=0,1,2,3,4 llamafactory-cli webchat config/webchat.yaml
```
/usr/bin/firefox "http://localhost:7861/"

## chat
```bash
cd /home/chuannong1/KJY/MultiLLM/LLaMA-Factory
conda activate llama_factory
CUDA_VISIBLE_DEVICES=0 llamafactory-cli chat config/chat.yaml
```

## api

```bash
cd /home/chuannong1/KJY/MultiLLM/LLaMA-Factory
conda activate llama_factory
API_PORT=8000 CUDA_VISIBLE_DEVICES=0 llamafactory-cli api config/api.yaml
```


## 导出和上传模型到huggingface

```bash
cd /home/chuannong1/KJY/MultiLLM/LLaMA-Factory
conda activate llama_factory
CUDA_VISIBLE_DEVICES=0 llamafactory-cli export config/merge_config.yaml
```


## ms-swift

```bash
conda activate ms-swift
cd /home/chuannong1/KJY/MultiLLM/ms-swift
CUDA_VISIBLE_DEVICES=0,1,2,3,4 NPROC_PER_NODE=5 swift sft \
  --model_type qwen2-vl-7b-instruct \
  --model_id_or_path Qwen/Qwen2-VL-7B-Instruct \
  --sft_type lora \
  --deepspeed zero3-offload \
  --dataset data/qwen2_vl_train.json \
  --val_dataset data/qwen2_vl_val.json \
```